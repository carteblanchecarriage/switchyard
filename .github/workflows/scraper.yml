name: Auto Scrape & Deploy

on:
  schedule:
    - cron: '0 */2 * * *'  # Every 2 hours
  workflow_dispatch:  # Manual trigger

permissions:
  contents: write  # For committing data updates
  pages: write     # For deploying to GitHub Pages
  id-token: write  # For requesting JWT

concurrency:
  group: pages
  cancel-in-progress: false

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          
      - name: Install dependencies
        run: npm ci
        
      - name: Install scraper dependencies
        run: cd scraper && npm ci
        
      - name: Run scraper
        run: node scraper/simple-scraper.js
        continue-on-error: true
        
      - name: Commit scraped data if changed
        run: |
          git config user.name "GitHub Actions"
          git config user.email "actions@github.com"
          git add data.json
          git diff --quiet && git diff --staged --quiet || (git commit -m "Auto-update: $(date '+%Y-%m-%d %H:%M')" && git push)
        continue-on-error: true
        
      - name: Build site with fresh data
        run: npm run build
        
      - name: Verify data.json in build
        run: |
          ls -la build/data.json
          cat build/data.json | head -c 200
          
      - name: Setup Pages
        uses: actions/configure-pages@v4
        
      - name: Upload to GitHub Pages
        uses: actions/upload-pages-artifact@v3
        with:
          path: './build'
          
      - name: Deploy to GitHub Pages  
        uses: actions/deploy-pages@v4
